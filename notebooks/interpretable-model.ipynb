{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an interpretable model\n",
    "In this model we're going to train an interpretable model.\n",
    "\n",
    "We'll cover the following topics in this notebook:\n",
    "\n",
    "* [Loading and preprocessing the data](#loading-and-preprocessing-the-data)\n",
    "* [Training the model](#training-the-model)\n",
    "* [Interpreting the model](#interpreting-the-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing the data\n",
    "First, we're going to load and preprocess the data for our model. We'll perform the following steps:\n",
    "\n",
    "* First, we load the dataset and split it into a  training and validation set.\n",
    "* Next, we collect the input variables for the model to train on.\n",
    "* After that, we collect the output variable for the model to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and splitting the dataset\n",
    "We're loading the training set from `data/processed/train.csv` and set aside 30% of the data for validation purposes.\n",
    "The rest we're using to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/train.csv')\n",
    "df_train, df_val = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features for training\n",
    "After we've loaded and split the dataset, we're going to extract the features from the dataset for training.\n",
    "We already know that we shouldn't be using the `SEX` column, because it's a protected attribute. So we'll drop it. \n",
    "\n",
    "Also, note that we're dropping the `default.payment.next.month` column from the feature set as we don't want our predicted variable to be part of the input variables for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop(['default.payment.next.month'], axis=1)\n",
    "x_val = df_val.drop(['default.payment.next.month'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the output variable\n",
    "Once we have the features for training, we're extracting the output variable that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['default.payment.next.month']\n",
    "y_val = df_val['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Now that we have the data ready for training, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA()), ('clf', RandomForestClassifier(n_jobs=-1))])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "pca = PCA()\n",
    "classifier = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "model = Pipeline([('pca', pca), ('clf', classifier)])\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the model\n",
    "After training, we're checking to make sure the performance of the model is what we expect it to be.\n",
    "We're using two measures for performance: \n",
    "\n",
    "* Accuracy\n",
    "* Receiver Operator Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8529629629629629"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show\n",
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "explainer = LimeTabular(predict_fn=model.predict_proba, data=x_train, random_state=1337)\n",
    "explanation = explainer.explain_local(x_val[:5], y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<!-- http://127.0.0.1:7001/1699467957776/ -->\n<iframe src=\"http://127.0.0.1:7001/1699467957776/\" width=100% height=800 frameBorder=\"0\"></iframe>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "show(explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}